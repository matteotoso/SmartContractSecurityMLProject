"""
Filtraggio delle vulnerabilità per consenso multi–tool
------------------------------------------------------

Questo script ha l’obiettivo di consolidare le vulnerabilità assegnate
ai chunk di codice, mantenendo solo quelle confermate da almeno due
strumenti di analisi statica differenti (Mythril, Slither, SmartCheck).

La logica adottata è la seguente:

1) Le vulnerabilità presenti nei chunk vengono raggruppate **solo in base
   alla categoria** (la sottocategoria non è più considerata).

2) Una categoria viene mantenuta se è stata rilevata da **almeno due tool
   differenti**, così da ottenere un segnale più affidabile.

3) Per ogni categoria confermata viene selezionata la **severity massima**
   tra tutte le segnalazioni appartenenti alla categoria.

4) La struttura dei chunk e degli eventuali sub–chunk rimane invariata,
   ma vengono mantenuti solo i chunk che hanno almeno una vulnerabilità
   dopo il filtraggio.

Il risultato finale è un file JSONL consolidato, utile per la costruzione
del dataset finale di apprendimento automatico.

Autore: Matteo Toso
Anno accademico: 2025
"""

import json
from collections import defaultdict
from pathlib import Path

# ============================================================
# 1. Configurazione file di input/output
# ============================================================

input_file = Path("Data/chunkDivision/contractsChunkSummary.jsonl")
output_file = Path("Data/chunkDivision/contractsChunkVulMerged.jsonl")

# Ordine di importanza per confronto delle severità
severity_order = {"Low": 1, "Medium": 2, "High": 3}

def max_severity(severities):
    """
    Restituisce la severity massima presente nella lista fornita.
    In caso di valori sconosciuti viene restituito 'Unknown'.
    """
    max_level = 0
    max_sev = "Unknown"
    for sev in severities:
        level = severity_order.get(sev, 0)
        if level > max_level:
            max_level = level
            max_sev = sev
    return max_sev


def filter_vulns(vulns):
    """
    Filtra le vulnerabilità di un chunk secondo un criterio di consenso:
    - Raggruppamento SOLO per categoria.
    - Una categoria è mantenuta solo se rilevata da >= 2 tool.
    - La severity finale è la massima tra quelle presenti.
    """
    grouped = defaultdict(list)

    # Raggruppamento per categoria
    for v in vulns:
        grouped[v["categoria"]].append(v)

    consensus_vulns = []

    for categoria, vlist in grouped.items():
        tools = set(v["tool"] for v in vlist)

        # Valida solo se almeno due tool confermano la categoria
        if len(tools) >= 2:
            final_sev = max_severity([v.get("severity", "Unknown") for v in vlist])
            consensus_vulns.append({
                "categoria": categoria,
                "tools": list(tools),
                "severity": final_sev
            })

    return consensus_vulns


# ============================================================
# 2. Applicazione del filtraggio ai chunk
# ============================================================

filtered_records = []

with open(input_file, "r", encoding="utf-8") as fin:
    for line in fin:
        if not line.strip():
            continue

        data = json.loads(line)
        contract = data["contract"]
        chunks = data.get("chunks", [])

        new_chunks = []

        for chunk in chunks:
            # Filtraggio vulnerabilità del chunk principale
            chunk_vulns = chunk.get("vulns", [])
            filtered_chunk_vulns = filter_vulns(chunk_vulns)

            # Filtraggio vulnerabilità degli eventuali sub–chunk
            new_sub_chunks = []
            for sub in chunk.get("sub_chunks", []):
                sub_vulns = sub.get("vulns", [])
                filtered_sub = filter_vulns(sub_vulns)
                if filtered_sub:
                    new_sub_chunks.append({
                        "lines_range": sub["lines_range"],
                        "token_count": sub["token_count"],
                        "vulns": filtered_sub
                    })

            # Mantieni il chunk solo se ha vulnerabilità o subchunk utili
            if filtered_chunk_vulns or new_sub_chunks:
                new_chunk = {
                    "id": chunk["id"],
                    "lines_range": chunk["lines_range"],
                    "token_count": chunk["token_count"]
                }
                if filtered_chunk_vulns:
                    new_chunk["vulns"] = filtered_chunk_vulns
                if new_sub_chunks:
                    new_chunk["sub_chunks"] = new_sub_chunks

                new_chunks.append(new_chunk)

        # Aggiungi il contratto solo se ha almeno un chunk valido
        if new_chunks:
            filtered_records.append({
                "contract": contract,
                "chunks": new_chunks
            })


# ============================================================
# 3. Scrittura dell’output finale
# ============================================================

with open(output_file, "w", encoding="utf-8") as fout:
    for record in filtered_records:
        fout.write(json.dumps(record, ensure_ascii=False) + "\n")

print(f"[✓] File creato: {output_file}")
print(f"[INFO] Contratti totali mantenuti: {len(filtered_records)}")
