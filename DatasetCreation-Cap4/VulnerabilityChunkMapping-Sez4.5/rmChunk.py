"""
Filtro dei chunk in base alla lunghezza del token
-------------------------------------------------

Questo script esegue una fase di pulizia sul dataset dei chunk generati
in precedenza. L’obiettivo è mantenere solamente le sequenze di codice
con un numero di token sufficiente per rappresentare informazioni utili
al modello basato su CodeBERT.

Vengono rimossi:
  - i chunk con meno di `min_tokens` token (bassa informatività),
  - i chunk con più di `max_tokens` token (limite architetturale),
  - i chunk padre i cui sub-chunk non soddisfano i criteri.

Il file risultante è un JSONL semplificato contenente soltanto chunk
validi per la fase di training.
"""

import json
from pathlib import Path

# ============================================================
#  Configurazione
# ============================================================

# File JSONL contenente i chunk completi con vulnerabilità
input_file = Path("Data/chunkDivision/contractsChunkVulMerged.jsonl")

# File di output contenente solo i chunk validi
output_file = Path("Data/chunkDivision/contractsChunkVulMergedReduced.jsonl")

# Range accettabile di token per ogni chunk
min_tokens = 50
max_tokens = 512


# ============================================================
#  Filtraggio chunk
# ============================================================

with open(input_file, "r", encoding="utf-8") as fin, \
     open(output_file, "w", encoding="utf-8") as fout:

    for line in fin:
        if not line.strip():
            continue

        data = json.loads(line)
        valid_chunks = []

        for chunk in data["chunks"]:

            # Caso A — Chunk che contiene sub-chunk
            if "sub_chunks" in chunk and chunk["sub_chunks"]:
                filtered_subs = [
                    sub for sub in chunk["sub_chunks"]
                    if min_tokens <= sub.get("token_count", 0) <= max_tokens
                ]

                # Il chunk viene mantenuto solo se conserva almeno un sub-chunk valido
                if filtered_subs:
                    valid_chunks.append({
                        "id": chunk.get("id"),
                        "sub_chunks": filtered_subs
                    })

            # Caso B — Chunk semplice (senza sub-chunk)
            else:
                if min_tokens <= chunk.get("token_count", 0) <= max_tokens:
                    valid_chunks.append(chunk)

        # Se il contratto non contiene più chunk validi, viene scartato
        if not valid_chunks:
            continue

        data["chunks"] = valid_chunks
        fout.write(json.dumps(data, ensure_ascii=False) + "\n")

print(f"[✓] Filtraggio completato. Risultato salvato in '{output_file}'")
